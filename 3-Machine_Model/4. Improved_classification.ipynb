{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a better classification model to classify images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import\n",
    "2. Preprocessing\n",
    "3. Define Model\n",
    "4. Train Model\n",
    "5. Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get processed images to be used as dataset to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 50\n",
    "\n",
    "pickle_in = open(\"X_improved.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_improved.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model using a pre-trained model (VGG16) with 3 added layers at the end - Flatten, Dense64 and Dense5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "\n",
    "model = VGG16(input_tensor=image_input, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(64))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "#third_last_layer = model.get_layer('block5_pool').output\n",
    "#out = Flatten(name='flatten')(third_last_layer)\n",
    "#custom_vgg_model = Model(image_input, out)\n",
    "\n",
    "#second_last_layer = custom_vgg_model.get_layer('flatten').output\n",
    "#out = Dense(64,activation='relu', name='dense64')(second_last_layer)\n",
    "#custom_vgg_model = Model(image_input, out)\n",
    "\n",
    "#last_layer = custom_vgg_model.get_layer('dense64').output\n",
    "#out = Dense(5,activation='softmax', name='output')(last_layer)\n",
    "#custom_vgg_model = Model(image_input, out)\n",
    "\n",
    "last_layer = model.get_layer('block5_pool').output\n",
    "tmp = Flatten(name='flatten')(last_layer)\n",
    "tmp = Dense(64,activation='relu',name='dense64')(tmp)\n",
    "out = Dense(5,activation='softmax', name='output')(tmp)\n",
    "custom_vgg_model = Model(image_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50, 50, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 50, 50, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense64 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 14,747,845\n",
      "Trainable params: 14,747,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                         optimizer='adadelta',\n",
    "                         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model with all layers freezed except for last three added layers. Providing a better classification with an accuracy between 65-75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3890 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "3890/3890 [==============================] - 73s 19ms/step - loss: 1.1089 - accuracy: 0.5728 - val_loss: 1.0042 - val_accuracy: 0.6005\n",
      "Epoch 2/12\n",
      "3890/3890 [==============================] - 66s 17ms/step - loss: 0.8416 - accuracy: 0.6730 - val_loss: 0.8589 - val_accuracy: 0.6420\n",
      "Epoch 3/12\n",
      "3890/3890 [==============================] - 64s 16ms/step - loss: 0.7829 - accuracy: 0.6997 - val_loss: 0.8367 - val_accuracy: 0.6651\n",
      "Epoch 4/12\n",
      "3890/3890 [==============================] - 67s 17ms/step - loss: 0.7354 - accuracy: 0.7224 - val_loss: 0.8093 - val_accuracy: 0.6813\n",
      "Epoch 5/12\n",
      "3890/3890 [==============================] - 71s 18ms/step - loss: 0.7040 - accuracy: 0.7339 - val_loss: 0.7999 - val_accuracy: 0.6859\n",
      "Epoch 6/12\n",
      "3890/3890 [==============================] - 64s 16ms/step - loss: 0.6772 - accuracy: 0.7445 - val_loss: 0.8544 - val_accuracy: 0.6559\n",
      "Epoch 7/12\n",
      "3890/3890 [==============================] - 64s 17ms/step - loss: 0.6536 - accuracy: 0.7602 - val_loss: 0.8368 - val_accuracy: 0.7067\n",
      "Epoch 8/12\n",
      "3890/3890 [==============================] - 70s 18ms/step - loss: 0.6355 - accuracy: 0.7604 - val_loss: 0.8096 - val_accuracy: 0.7044\n",
      "Epoch 9/12\n",
      "3890/3890 [==============================] - 71s 18ms/step - loss: 0.6190 - accuracy: 0.7658 - val_loss: 0.8815 - val_accuracy: 0.6905\n",
      "Epoch 10/12\n",
      "3890/3890 [==============================] - 72s 19ms/step - loss: 0.5988 - accuracy: 0.7704 - val_loss: 0.7991 - val_accuracy: 0.7136\n",
      "Epoch 11/12\n",
      "3890/3890 [==============================] - 83s 21ms/step - loss: 0.5853 - accuracy: 0.7856 - val_loss: 0.8196 - val_accuracy: 0.6905\n",
      "Epoch 12/12\n",
      "3890/3890 [==============================] - 75s 19ms/step - loss: 0.5642 - accuracy: 0.7938 - val_loss: 0.8464 - val_accuracy: 0.6882\n"
     ]
    }
   ],
   "source": [
    "X = X/255.0\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "custom_vgg_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                         optimizer='adadelta',\n",
    "                         metrics=['accuracy'])    \n",
    "    \n",
    "history = custom_vgg_model.fit(X,y,epochs=12, validation_split=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Model to be used for another file or at another time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model.save(\"improved_classification.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
